# ğŸš€ Data Engineering ETL Pipeline with Airflow & PostgreSQL

This project demonstrates a complete **ETL Data Pipeline** using:
- **Python** ğŸ
- **PostgreSQL** ğŸ˜
- **Apache Airflow** ğŸŒ¬ï¸
- **Docker** ğŸ³

---

## ğŸ“Œ Project Overview
The pipeline processes sales data:
1. **Extract**: Load data from a CSV file.  
2. **Transform**: Clean data and calculate `total_price = quantity * unit_price`.  
3. **Load**: Store the transformed data in PostgreSQL.  
4. **Orchestration**: Manage and schedule the pipeline using Airflow.  

---

## ğŸ“‚ Project Structure
data-engineering-sales-pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ sales_pipeline_dag.py      # Airflow DAG
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract.py                 # Extract step
â”‚   â”œâ”€â”€ transform.py               # Transform step
â”‚   â””â”€â”€ load.py                    # Load step
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sales_data_sample.csv      # Sample sales data
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ create_tables.sql          # PostgreSQL schema
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # Project documentation
